FRONT_PORT= # Vite default is 5173
BACK_PORT= # FastAPI default is 5000
OLLAMA_URL= # Ollama's default is http://localhost:11434 for locally hosted models
# Set the model you want to use and ensure the roles it uses are correct, based on the documentation of that model.
OLLAMA_MODEL= # e.g., gemma3:4b
USER_ROLE= # user / human
ASSISTANT_ROLE= # assistant / model
OLLAMA_EMBEDDING_MODEL=nomic-embed-text # Recommended for text embeddings, but can be changed based on your needs.